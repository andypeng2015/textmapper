// generated by Textmapper; DO NOT EDIT

import * as common from './common';
import {TokenType} from './token';
import * as lexer from './lexer';
import * as listener from './listener';
import * as ptables from './parser_tables';


export type SyntaxError = {
  line: number;
  offset: number;
  endoffset: number;
};

export function ErrorMsg(err : SyntaxError) : string {
  return "syntax error at line " + err.line;
}

function lalr(action: number, next: number): number {
  let a = -action - 3;
  for (; ptables.tmLalr[a] >= 0; a += 2) {
    if (ptables.tmLalr[a] === next) {
      break;
    }
  }
  return ptables.tmLalr[a + 1];
}

function fixTrailingWS(lhs: common.StackEntry, rhs: common.StackEntry[]) : void {
  let last = rhs.length - 1;
  if (last < 0) {
    return;
  }
  while (last >= 0 && rhs[last].sym.offset === rhs[last].sym.endoffset) {
    last--;
  }
  if (last >= 0) {
    lhs.sym.endoffset = rhs[last].sym.endoffset;
  } else {
    lhs.sym.endoffset = lhs.sym.offset;
  }
}

function gotoState(state: number, symbol: number) : number {
  let min = ptables.tmGoto[symbol];
  let max = ptables.tmGoto[symbol + 1];

  if (max - min < 32) {
    for (let i = min; i < max; i += 2) {
      if (ptables.tmFromTo[i] === state) {
        return ptables.tmFromTo[i + 1];
      }
    }
  } else {
    while (min < max) {
      let e = ((min + max) >> 1) & ~1;
      let i = ptables.tmFromTo[e];
      if (i === state) {
        return ptables.tmFromTo[e + 1];
      } else if (i < state) {
        min = e + 2;
      } else {
        max = e;
      }
    }
  }
  return -1;
}

// Parser is a table-driven LALR parser for json.
export class Parser {
  _listener: listener.Listener;
  _next: common.Symbol;
  // Tokens to be reported with the next shift. Only non-empty when next.symbol != noToken.
  _pending: common.Symbol[];
  constructor(listener: listener.Listener) {
    this._listener = listener;
    this._next = new common.Symbol(TokenType.UNAVAILABLE, 0, 0);
    this._pending = [];
  }

  parse(lexer: lexer.Lexer) : { err? : SyntaxError } {
    return this.doParse(0, 27, lexer);
  }

  private doParse(start: number, end: number, lexer: lexer.Lexer) : {  err?: SyntaxError } {
    this._pending = [];
    let state = start;

    let stack: common.StackEntry[] | null = [{sym: new common.Symbol(TokenType.UNAVAILABLE, 0, 0), state: state }];
    this.fetchNext(lexer, stack);

    while (state !== end) {
      let action = ptables.tmAction[state];
      if (action < -2) {
        // Lookahead is needed.
        if (this._next.symbol === ptables.noToken) {
          this.fetchNext(lexer, stack);
        }
        action = lalr(action, this._next.symbol);
      }
      if (action >= 0) {
        // Reduce.
        let rule = action;
        let ln = ptables.tmRuleLen[rule];


        let entry : common.StackEntry = { sym: new common.Symbol(ptables.tmRuleSymbol[rule], 0, 0), state: 0 };
        let rhs = stack.slice(stack.length - ln);
        if (ln === 0) {
          if (this._next.symbol === ptables.noToken) {
            this.fetchNext(lexer, stack);
          }
          entry.sym.offset = this._next.offset;
          entry.sym.endoffset = this._next.offset;
        } else {
          entry.sym.offset = rhs[0].sym.offset;
          entry.sym.endoffset = rhs[ln - 1].sym.endoffset;
        }
        this.applyRule(rule, entry, stack, lexer);
        stack = stack.slice(0, stack.length - rhs.length);
        if (common.debugSyntax) {
          common.debugLog("reduced to", ptables.symbolName(entry.sym.symbol));
        }
        state = gotoState(stack[stack.length - 1].state, entry.sym.symbol);
        entry.state = state;
        stack.push(entry);

      } else if (action === -1) {
        // Shift.
        if (this._next.symbol === ptables.noToken) {
          this.fetchNext(lexer, stack);
        }
        state = gotoState(state, this._next.symbol);
        if (state >= 0) {
          stack.push({
            sym:   this._next.copy(),
            state: state,
          });
          if (common.debugSyntax) {
            common.debugLog("lookahead shift:", ptables.symbolName(this._next.symbol), "(", lexer.text(), ")");
          }
          this.flush(this._next);
          if (this._next.symbol !== ptables.eoiToken) {
      switch (this._next.symbol) {
        case TokenType.JSONSTRING:
          this._listener(listener.NodeType.JSONString, this._next.offset, this._next.endoffset);
          break;
      }
            this._next.symbol = ptables.noToken;
          }
        }
      }

      if (action === -2 || state === -1) {
        break;
      }
    }

    if (state !== end) {
      if (this._next.symbol === ptables.noToken) {
        this.fetchNext(lexer, stack);
      }
      let err : SyntaxError = {
        line:      lexer.line(),
        offset:    this._next.offset,
        endoffset: this._next.endoffset
      }
      return { err: err };
    }


    return { };

  }

  private fetchNext(lexer: lexer.Lexer, stack: common.StackEntry[]) : void {
    restart: while (true) {
      let tok = lexer.next();
      switch (tok) {
        case TokenType.MULTILINECOMMENT:
        case TokenType.INVALID_TOKEN:
          let { start, end } = lexer.pos();
          this._pending.push(new common.Symbol(tok, start, end));
          continue restart;
      }
      let { start, end } = lexer.pos();
      this._next.symbol = tok;
      this._next.offset = start;
      this._next.endoffset = end;
      break;
    }
  }

  private applyRule(rule: number, lhs: common.StackEntry, stack: common.StackEntry[], lexer: lexer.Lexer) : void {
    let nt = ptables.tmRuleType[rule];
    if (nt !== 0) {
      this._listener(nt, lhs.sym.offset, lhs.sym.endoffset);
    }
  }

  reportIgnoredToken(tok: common.Symbol) : void {
    let t: listener.NodeType;
    switch (tok.symbol) {
      case TokenType.MULTILINECOMMENT:
        t = listener.NodeType.MultiLineComment;
        break;
      case TokenType.INVALID_TOKEN:
        t = listener.NodeType.InvalidToken;
        break;
      default:
        return;
    }
    if (common.debugSyntax) {
      common.debugLog("ignored:", TokenType[tok.symbol], "as", t);
    }
    this._listener(t, tok.offset, tok.endoffset);
  }

  // flush reports all pending tokens up to a given symbol.
  private flush(sym: common.Symbol) : void {
    if (this._pending.length > 0) {
      for (let i = 0; i < this._pending.length; i++) {
        let tok = this._pending[i];
        if (tok.endoffset > sym.endoffset) {
          // Note: this copying should not happen during normal operation, only
          // during error recovery.
          this._pending = this._pending.slice(i);
          return;
        }
        this.reportIgnoredToken(tok);
      }
      this._pending = [];
    }
  }

};

